{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import spacy\n",
    "from synth_data import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/eddiecavallin/.cache/kagglehub/datasets/mikeortman/wikipedia-sentences/versions/3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mikeortman/wikipedia-sentences\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,\n",
       " ['Brian C. McGing is a papyrologist and ancient historian, who specializes in the Hellenistic period.',\n",
       "  'Ford gained national attention when Miley Cyrus brought them as her date to The Foundation for AIDS Research (AMFAR) gala in 2015.',\n",
       "  'Its specific name \"limbatus\" is from the Latin meaning \"black-edged\" and refers to the colored markings of this species.',\n",
       "  'Skarbino is a village in Kardzhali Municipality, Kardzhali Province, southern Bulgaria.',\n",
       "  'Dasai Chowdhary is an Indian politician.',\n",
       "  'Berdusco also played internationally for Canada and scored one of its most memorable goals in a friendly against Brazil in 1994.',\n",
       "  'AppleDouble leaves the data fork in its original format, allowing it to be edited by normal Unix utilities.',\n",
       "  'Kronenbourg 1664 is now produced in the UK by Heineken after being bought from Scottish & Newcastle.',\n",
       "  \"In J. R. R. Tolkien's legendarium, the Battle of the Morannon or Battle of the Black Gate is a fictional event that took place at the end of the War of the Ring.\",\n",
       "  'The Antilopinae are a subfamily of Bovidae.'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def sample_random_lines(path, k=200_000):\n",
    "    \"\"\"\n",
    "    Randomly sample k lines from a very large file\n",
    "    using reservoir sampling.\n",
    "    Ensures unbiased random sampling.\n",
    "    \"\"\"\n",
    "    reservoir = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            if len(reservoir) < k:\n",
    "                reservoir.append(line)\n",
    "            else:\n",
    "                # Replace elements with decreasing probability\n",
    "                j = random.randint(1, i)\n",
    "                if j <= k:\n",
    "                    reservoir[j - 1] = line\n",
    "\n",
    "    return reservoir\n",
    "\n",
    "\n",
    "# ---- USE IT ----\n",
    "\n",
    "wiki_path = \"wikisent2.txt\"   # change to your actual filename\n",
    "\n",
    "random.seed(42)\n",
    "clean_sentences = sample_random_lines(wiki_path, k=200_000)\n",
    "\n",
    "len(clean_sentences), clean_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic examples per type:\n",
      "  comma splices: 3000\n",
      "  comma deletions: 3000\n",
      "  comma insertions: 3000\n",
      "Total rows in df_syn: 16505\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>error_type</th>\n",
       "      <th>synthetic_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Song is professor of law and political science...</td>\n",
       "      <td>0</td>\n",
       "      <td>orig</td>\n",
       "      <td>delete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He played 18 seasons and 346 matches in the, N...</td>\n",
       "      <td>1</td>\n",
       "      <td>comma_inserted</td>\n",
       "      <td>insert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Behind the scenes Imbruglia quit the serial.</td>\n",
       "      <td>0</td>\n",
       "      <td>orig</td>\n",
       "      <td>insert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The club currently has many teams within the o...</td>\n",
       "      <td>1</td>\n",
       "      <td>comma_deleted</td>\n",
       "      <td>delete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On June 29 1995, the drinking water supply in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>comma_deleted</td>\n",
       "      <td>delete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label      error_type  \\\n",
       "0  Song is professor of law and political science...      0            orig   \n",
       "1  He played 18 seasons and 346 matches in the, N...      1  comma_inserted   \n",
       "2       Behind the scenes Imbruglia quit the serial.      0            orig   \n",
       "3  The club currently has many teams within the o...      1   comma_deleted   \n",
       "4  On June 29 1995, the drinking water supply in ...      1   comma_deleted   \n",
       "\n",
       "  synthetic_source  \n",
       "0           delete  \n",
       "1           insert  \n",
       "2           insert  \n",
       "3           delete  \n",
       "4           delete  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "df_synthetic = build_synthetic_comma_dataset(clean_sentences, max_per_type=3000)\n",
    "df_synthetic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synthetic.to_csv(\"df_synthetic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    9000\n",
       "0    7505\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_synthetic.head()\n",
    "df_synthetic[\"label\"] = df_synthetic[\"label\"].astype(int)\n",
    "df_synthetic[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 11553\n",
      "Val size: 2476\n",
      "Test size: 2476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16200</th>\n",
       "      <td>Once the sea all around Lesbos rose in such hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10190</th>\n",
       "      <td>147 Squadron, often referred to as the Flying ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16286</th>\n",
       "      <td>The Administrator is nominated by the Presiden...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11438</th>\n",
       "      <td>Warner W. Holzinger of the 2nd Platoon, Troop ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5815</th>\n",
       "      <td>Their lord was the monarch ,, they were admini...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "16200  Once the sea all around Lesbos rose in such hi...      1\n",
       "10190  147 Squadron, often referred to as the Flying ...      0\n",
       "16286  The Administrator is nominated by the Presiden...      1\n",
       "11438  Warner W. Holzinger of the 2nd Platoon, Troop ...      1\n",
       "5815   Their lord was the monarch ,, they were admini...      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_synthetic must have columns: 'sentence' (str), 'label' (0/1)\n",
    "df_synthetic[\"label\"] = df_synthetic[\"label\"].astype(int)\n",
    "\n",
    "X = df_synthetic[\"sentence\"]\n",
    "y = df_synthetic[\"label\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "train_df = pd.DataFrame({\"sentence\": X_train, \"label\": y_train})\n",
    "val_df   = pd.DataFrame({\"sentence\": X_val,   \"label\": y_val})\n",
    "test_df  = pd.DataFrame({\"sentence\": X_test,  \"label\": y_test})\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Val size:\", len(val_df))\n",
    "print(\"Test size:\", len(test_df))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 11553\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 2476\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 2476\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrap into HF Datasets\n",
    "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_ds   = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "test_ds  = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "\n",
    "raw_datasets = DatasetDict({\n",
    "    \"train\": train_ds,\n",
    "    \"validation\": val_ds,\n",
    "    \"test\": test_ds,\n",
    "})\n",
    "\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/fin_proj/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d922675fdc472099c3a825cce85b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11553 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005bb3feac324e99943da57ce0b52ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4427aa3d69245409e874c9da98ce430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 11553\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2476\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2476\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DistilBERT tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_batch, batched=True)\n",
    "\n",
    "# Keep only what we need\n",
    "cols_to_keep = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(\n",
    "    [c for c in tokenized_datasets[\"train\"].column_names if c not in cols_to_keep]\n",
    ")\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    ")\n",
    "\n",
    "# Device (M1/M2 â†’ 'mps', else CPU/CUDA)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "val_dataset   = tokenized_datasets[\"validation\"]\n",
    "test_dataset  = tokenized_datasets[\"test\"]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/fin_proj/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Optimizer & scheduler\n",
    "epochs = 3\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "num_training_steps = epochs * len(train_loader)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * num_training_steps),\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71b4442f8b444a6acbca3c34008b444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/723 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 avg training loss: 0.4474\n",
      "Epoch 1 val loss: 0.3306, val acc: 0.8518\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15678d1e02d4c578a39771588cd7721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/723 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 avg training loss: 0.2671\n",
      "Epoch 2 val loss: 0.3314, val acc: 0.8506\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39479e7525444894886042ff7d7a29e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/723 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 avg training loss: 0.1844\n",
      "Epoch 3 val loss: 0.3670, val acc: 0.8534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for batch in loop:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"\\nEpoch {epoch+1} avg training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels,\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1} val loss: {avg_val_loss:.4f}, val acc: {val_acc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic test set performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8406    0.8570    0.8487      1126\n",
      "           1     0.8788    0.8644    0.8715      1350\n",
      "\n",
      "    accuracy                         0.8611      2476\n",
      "   macro avg     0.8597    0.8607    0.8601      2476\n",
      "weighted avg     0.8614    0.8611    0.8612      2476\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 965  161]\n",
      " [ 183 1167]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "print(\"Synthetic test set performance:\")\n",
    "print(classification_report(all_labels, all_preds, digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "val_df  = pd.read_csv(\"validation.csv\")\n",
    "\n",
    "\n",
    "test_df[\"corr_list\"] = test_df[\"corrections\"].apply(parse_corrections)\n",
    "val_df[\"corr_list\"]  = val_df[\"corrections\"].apply(parse_corrections)\n",
    "\n",
    "test_df[\"comma_candidate\"] = test_df.apply(\n",
    "    lambda row: comma_change_row(row[\"sentence\"], row[\"corr_list\"]), axis=1\n",
    ")\n",
    "val_df[\"comma_candidate\"] = val_df.apply(\n",
    "    lambda row: comma_change_row(row[\"sentence\"], row[\"corr_list\"]), axis=1\n",
    ")\n",
    "\n",
    "test_comma = test_df[test_df[\"comma_candidate\"]]\n",
    "val_comma  = val_df[val_df[\"comma_candidate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Gutenberg Data\n",
    "\n",
    "Here I will construct the Gutenberg dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not define our own grammar, as this would be quite complicated. Instead we decide to import a pretrained parser to do parts of speech tagging. We decided on using the spaCy NLP package. As a group, we are aware that spaCy has the capability of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Make sure you've done: python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import CFG, ChartParser\n",
    "import helpers\n",
    "\n",
    "grammar_str = r\"\"\"\n",
    "S -> CLAUSE PUNCT\n",
    "S -> CLAUSE CONJ CLAUSE PUNCT\n",
    "S -> CLAUSE COMMA CONJ CLAUSE PUNCT\n",
    "S -> INTRO COMMA CLAUSE PUNCT\n",
    "\n",
    "INTRO -> ADV\n",
    "INTRO -> ADV ADV\n",
    "INTRO -> PP\n",
    "\n",
    "CLAUSE -> NP VP\n",
    "CLAUSE -> NP_LIST VP\n",
    "CLAUSE -> NP VP_LIST\n",
    "\n",
    "NP -> PRON\n",
    "NP -> DET N\n",
    "NP -> N\n",
    "NP -> NP_LIST\n",
    "NP -> NP APPOS\n",
    "\n",
    "NP_LIST -> NP COMMA NP\n",
    "NP_LIST -> NP COMMA NP_LIST\n",
    "\n",
    "APPOS -> COMMA NP COMMA\n",
    "\n",
    "VP -> V\n",
    "VP -> V NP\n",
    "VP -> V ADV\n",
    "VP -> V NP ADV\n",
    "VP -> AUX V\n",
    "VP -> AUX V NP\n",
    "VP -> AUX V ADV\n",
    "VP -> AUX V NP ADV\n",
    "VP -> V NP PP\n",
    "VP -> AUX V NP PP\n",
    "\n",
    "VP_LIST -> VP COMMA VP\n",
    "VP_LIST -> VP COMMA VP_LIST\n",
    "\n",
    "PP -> P NP\n",
    "\n",
    "PRON -> 'PRON'\n",
    "DET  -> 'DET'\n",
    "N    -> 'N'\n",
    "V    -> 'V'\n",
    "AUX  -> 'AUX'\n",
    "P    -> 'P'\n",
    "CONJ -> 'CONJ'\n",
    "PUNCT -> 'PUNCT'\n",
    "COMMA -> 'COMMA'\n",
    "ADV -> 'ADV'\n",
    "\"\"\"\n",
    "\n",
    "grammar = CFG.fromstring(grammar_str)\n",
    "s_parser = ChartParser(grammar)\n",
    "\n",
    "clause_nt = nltk.Nonterminal('CLAUSE')\n",
    "clause_grammar = CFG(clause_nt, grammar.productions())\n",
    "clause_parser = ChartParser(clause_grammar)\n",
    "\n",
    "# hook into helpers so parses_as_sentence / parses_as_clause / is_cfg_comma_splice use this grammar\n",
    "helpers.s_parser = s_parser\n",
    "helpers.clause_parser = clause_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import is_cfg_comma_splice\n",
    "\n",
    "def cfg_predict_label(sentence: str) -> int:\n",
    "    \"\"\"\n",
    "    Return 1 if the CFG-based rule thinks this is a comma splice,\n",
    "    else 0. This is *not* a perfect match to your 'comma-only edit' label,\n",
    "    but we can still evaluate it as a baseline against that label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(is_cfg_comma_splice(sentence))\n",
    "    except Exception:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"I went home, I slept.\",\n",
    "    \"I went home, and I slept.\",\n",
    "    \"I went home and I slept.\",\n",
    "    \"Every person needs to know a bit about math, so they can manage daily life.\",\n",
    "    \"Every person needs to know a bit about math.\",\n",
    "]\n",
    "\n",
    "for s in examples:\n",
    "    print(s, \"=>\", is_cfg_comma_splice(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "records = []\n",
    "with open(\"lang-8_data.dat\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            records.append(obj)\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for rec in records:\n",
    "    journal_id = rec[0]\n",
    "    sentence_id = rec[1]\n",
    "    learning_language = rec[2]\n",
    "    native_language = rec[3]\n",
    "    learner_sents = rec[4]\n",
    "    corrections = rec[5]\n",
    "\n",
    "    for sent, corr_list in zip(learner_sents, corrections):\n",
    "        rows.append({\n",
    "            \"journal_id\": journal_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"learning_language\": learning_language,\n",
    "            \"native_language\": native_language,\n",
    "            \"sentence\": sent,\n",
    "            \"corrections\": corr_list\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"learning_language\"] == \"English\"]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Take the first correction as our reference target\n",
    "# df[\"first_corr\"] = df[\"corrections\"].apply(\n",
    "#     lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None\n",
    "# )\n",
    "\n",
    "\n",
    "# # Label whether the only edits between sentence and correction are comma edits\n",
    "# df[\"comma_only_error\"] = df.apply(\n",
    "#     lambda row: comma_only_edit(row[\"sentence\"], row[\"first_corr\"]),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# df[[\"sentence\", \"first_corr\", \"comma_only_error\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only keep rows where we actually have a correction\n",
    "# df_clean = df[df[\"first_corr\"].notnull()].copy()\n",
    "\n",
    "# # Our label: 1 = pure comma error, 0 = not pure comma error\n",
    "# df_clean[\"label\"] = df_clean[\"comma_only_error\"].astype(int)\n",
    "\n",
    "# df_clean[[\"sentence\", \"first_corr\", \"label\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save to CSV\n",
    "# df_clean.to_csv(\"df_clean.csv\", index=False)\n",
    "df_clean = pd.read_csv('df_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1163569\n",
       "1       3015\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset size: 13015\n",
      "label\n",
      "0    10000\n",
      "1     3015\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_pos = df_clean[df_clean[\"label\"] == 1]\n",
    "df_neg = df_clean[df_clean[\"label\"] == 0].sample(n=10000, random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([df_pos, df_neg]).sample(frac=1, random_state=42)\n",
    "df_balanced = pd.concat([df_pos, df_neg]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Balanced dataset size:\", len(df_balanced))\n",
    "print(df_balanced[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 9110\n",
      "Validation size: 1952\n",
      "Test size: 1953\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_balanced[\"sentence\"]\n",
    "y = df_balanced[\"label\"]\n",
    "\n",
    "# Train / temp split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Validation / Test split\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Validation size:\", len(X_val))\n",
    "print(\"Test size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lang-8 size after cleaning: 1166583\n",
      "                                            sentence  label\n",
      "0  I will appreciate it if you correct my sentences.      0\n",
      "1  It's been getting colder these days here in Ja...      0\n",
      "2  The summer weather in Japan is not agreeable t...      0\n",
      "3  So, as the winter is coming, I'm getting to fe...      0\n",
      "4                    It is the very exciting season.      0\n"
     ]
    }
   ],
   "source": [
    "# Start from df_clean (your Lang-8 data)\n",
    "df_clean[\"label\"] = df_clean[\"label\"].astype(int)\n",
    "\n",
    "# Keep only the columns we need\n",
    "lang8_df = df_clean[[\"sentence\", \"label\"]].copy()\n",
    "\n",
    "# Drop rows where sentence is missing\n",
    "lang8_df = lang8_df.dropna(subset=[\"sentence\"])\n",
    "\n",
    "# Force everything to string (tokenizer wants strings)\n",
    "lang8_df[\"sentence\"] = lang8_df[\"sentence\"].astype(str)\n",
    "\n",
    "print(\"Lang-8 size after cleaning:\", len(lang8_df))\n",
    "print(lang8_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using subset for evaluation: 50000\n"
     ]
    }
   ],
   "source": [
    "# Optional: subsample for evaluation, e.g. 50k sentences\n",
    "lang8_df = lang8_df.sample(n=50_000, random_state=42)\n",
    "print(\"Using subset for evaluation:\", len(lang8_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417cec5b07cf429e9c6555794fff8137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "lang8_ds = Dataset.from_pandas(lang8_df.reset_index(drop=True))\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "lang8_tokenized = lang8_ds.map(tokenize_batch, batched=True)\n",
    "\n",
    "cols_to_keep = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "lang8_tokenized = lang8_tokenized.remove_columns(\n",
    "    [c for c in lang8_tokenized.column_names if c not in cols_to_keep]\n",
    ")\n",
    "lang8_tokenized.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lang-8 evaluation (synthetic-trained model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9982    0.8043    0.8908     49871\n",
      "           1     0.0058    0.4419    0.0115       129\n",
      "\n",
      "    accuracy                         0.8033     50000\n",
      "   macro avg     0.5020    0.6231    0.4511     50000\n",
      "weighted avg     0.9956    0.8033    0.8885     50000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40109  9762]\n",
      " [   72    57]]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "lang8_loader = DataLoader(lang8_tokenized, batch_size=32)\n",
    "\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in lang8_loader:\n",
    "        ids = batch[\"input_ids\"].to(device)\n",
    "        mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        logits = model(ids, attention_mask=mask).logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "print(\"Lang-8 evaluation (synthetic-trained model):\")\n",
    "print(classification_report(all_labels, all_preds, digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        ngram_range=(1,2),       # unigrams + bigrams\n",
    "        max_features=50000,      # cap vocab size\n",
    "        lowercase=True\n",
    "    )),\n",
    "    ('clf', LogisticRegression(\n",
    "        class_weight=\"balanced\", # helps with imbalance\n",
    "        max_iter=200\n",
    "    ))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "print(\"Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred, digits=4))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Test Performance\")\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame({\"sentence\": X_train, \"label\": y_train.astype(int)})\n",
    "val_df   = pd.DataFrame({\"sentence\": X_val,   \"label\": y_val.astype(int)})\n",
    "test_df  = pd.DataFrame({\"sentence\": X_test,  \"label\": y_test.astype(int)})\n",
    "\n",
    "train_df.head(), val_df.head(), test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_ds   = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "test_ds  = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "\n",
    "raw_datasets = DatasetDict({\n",
    "    \"train\": train_ds,\n",
    "    \"validation\": val_ds,\n",
    "    \"test\": test_ds,\n",
    "})\n",
    "\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_batch, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(\n",
    "    [col for col in tokenized_datasets[\"train\"].column_names if col not in (\"input_ids\", \"attention_mask\", \"label\")]\n",
    ")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1\": f1_metric.compute(predictions=preds, references=labels, average=\"binary\")[\"f1\"],\n",
    "    }\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"comma_error_distilbert\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# CFG predictions on test sentences\n",
    "y_test_cfg = X_test.apply(cfg_predict_label).to_numpy()\n",
    "\n",
    "print(\"CFG baseline on test set\")\n",
    "print(classification_report(y_test, y_test_cfg, digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_cfg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fin_proj)",
   "language": "python",
   "name": "fin_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
